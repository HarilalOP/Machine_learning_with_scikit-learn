{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53783e35",
   "metadata": {},
   "source": [
    "# üìù Exercise M6.01\n",
    "\n",
    "The aim of this notebook is to investigate if we can tune the hyperparameters\n",
    "of a bagging regressor and evaluate the gain obtained.\n",
    "\n",
    "We will load the California housing dataset and split it into a training and\n",
    "a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017a0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6499c",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">If you want a deeper overview regarding this dataset, you can refer to the\n",
    "Appendix - Datasets description section at the end of this MOOC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976efbb",
   "metadata": {},
   "source": [
    "Create a `BaggingRegressor` and provide a `DecisionTreeRegressor`\n",
    "to its parameter `base_estimator`. Train the regressor and evaluate its\n",
    "statistical performance on the testing set using the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4c20e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic mean absolute error of the bagging regressor:\n",
      "36.93 k$\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagging = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_jobs=2)\n",
    "bagging.fit(data_train, target_train)\n",
    "target_predicted = bagging.predict(data_test)\n",
    "print(f\"Basic mean absolute error of the bagging regressor:\\n\"\n",
    "      f\"{mean_absolute_error(target_test, target_predicted):.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042cd91",
   "metadata": {},
   "source": [
    "Now, create a `RandomizedSearchCV` instance using the previous model and\n",
    "tune the important parameters of the bagging regressor. Find the best\n",
    "parameters  and check if you are able to find a set of parameters that\n",
    "improve the default regressor still using the mean absolute error as a\n",
    "metric.\n",
    "\n",
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\">You can list the bagging regressor's parameters using the <tt class=\"docutils literal\">get_params</tt>\n",
    "method.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "963be09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_estimator__ccp_alpha\n",
      "base_estimator__criterion\n",
      "base_estimator__max_depth\n",
      "base_estimator__max_features\n",
      "base_estimator__max_leaf_nodes\n",
      "base_estimator__min_impurity_decrease\n",
      "base_estimator__min_impurity_split\n",
      "base_estimator__min_samples_leaf\n",
      "base_estimator__min_samples_split\n",
      "base_estimator__min_weight_fraction_leaf\n",
      "base_estimator__random_state\n",
      "base_estimator__splitter\n",
      "base_estimator\n",
      "bootstrap\n",
      "bootstrap_features\n",
      "max_features\n",
      "max_samples\n",
      "n_estimators\n",
      "n_jobs\n",
      "oob_score\n",
      "random_state\n",
      "verbose\n",
      "warm_start\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "for param in bagging.get_params().keys():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06170184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": randint(10, 30),\n",
    "    \"max_samples\": [0.5, 0.8, 1.0],\n",
    "    \"max_features\": [0.5, 0.8, 1.0],\n",
    "    \"base_estimator__max_depth\": randint(3, 10),\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    bagging, param_grid, n_iter=20, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "_ = search.fit(data_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2dc9a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_base_estimator__max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>39.073592</td>\n",
       "      <td>0.917953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>39.430291</td>\n",
       "      <td>2.151766</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>41.250653</td>\n",
       "      <td>1.023073</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>41.354466</td>\n",
       "      <td>1.088306</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>42.630080</td>\n",
       "      <td>0.976444</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>42.699593</td>\n",
       "      <td>1.142985</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>43.695129</td>\n",
       "      <td>1.392403</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>45.479642</td>\n",
       "      <td>1.524456</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>45.801751</td>\n",
       "      <td>1.256155</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>47.667432</td>\n",
       "      <td>1.099928</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>48.216319</td>\n",
       "      <td>0.665998</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>48.873638</td>\n",
       "      <td>1.216368</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>51.506750</td>\n",
       "      <td>1.150217</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.807224</td>\n",
       "      <td>1.038959</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.937045</td>\n",
       "      <td>0.940036</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>52.145643</td>\n",
       "      <td>0.990108</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>55.584476</td>\n",
       "      <td>1.351131</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>56.131745</td>\n",
       "      <td>1.035994</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>56.919644</td>\n",
       "      <td>2.764406</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>60.905433</td>\n",
       "      <td>1.657850</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_max_samples param_max_features  \\\n",
       "3                  22               0.8                0.8   \n",
       "16                 13               1.0                0.8   \n",
       "5                  16               1.0                1.0   \n",
       "9                  15               0.8                1.0   \n",
       "2                  29               1.0                1.0   \n",
       "12                 25               0.8                1.0   \n",
       "13                 10               1.0                0.8   \n",
       "0                  21               0.8                0.5   \n",
       "18                 12               1.0                1.0   \n",
       "8                  25               0.5                1.0   \n",
       "10                 19               0.8                0.8   \n",
       "14                 26               0.8                0.5   \n",
       "11                 29               0.5                1.0   \n",
       "1                  20               1.0                0.8   \n",
       "6                  27               0.8                0.8   \n",
       "15                 10               1.0                1.0   \n",
       "19                 29               0.8                0.5   \n",
       "7                  24               0.5                1.0   \n",
       "17                 18               1.0                0.5   \n",
       "4                  22               1.0                0.5   \n",
       "\n",
       "   param_base_estimator__max_depth  mean_test_score  std_test_score  \\\n",
       "3                                9        39.073592        0.917953   \n",
       "16                               9        39.430291        2.151766   \n",
       "5                                8        41.250653        1.023073   \n",
       "9                                8        41.354466        1.088306   \n",
       "2                                7        42.630080        0.976444   \n",
       "12                               7        42.699593        1.142985   \n",
       "13                               7        43.695129        1.392403   \n",
       "0                                8        45.479642        1.524456   \n",
       "18                               6        45.801751        1.256155   \n",
       "8                                5        47.667432        1.099928   \n",
       "10                               5        48.216319        0.665998   \n",
       "14                               7        48.873638        1.216368   \n",
       "11                               4        51.506750        1.150217   \n",
       "1                                4        51.807224        1.038959   \n",
       "6                                4        51.937045        0.940036   \n",
       "15                               4        52.145643        0.990108   \n",
       "19                               4        55.584476        1.351131   \n",
       "7                                3        56.131745        1.035994   \n",
       "17                               4        56.919644        2.764406   \n",
       "4                                3        60.905433        1.657850   \n",
       "\n",
       "    rank_test_score  \n",
       "3                 1  \n",
       "16                2  \n",
       "5                 3  \n",
       "9                 4  \n",
       "2                 5  \n",
       "12                6  \n",
       "13                7  \n",
       "0                 8  \n",
       "18                9  \n",
       "8                10  \n",
       "10               11  \n",
       "14               12  \n",
       "11               13  \n",
       "1                14  \n",
       "6                15  \n",
       "15               16  \n",
       "19               17  \n",
       "7                18  \n",
       "17               19  \n",
       "4                20  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "cv_results = pd.DataFrame(search.cv_results_)\n",
    "cv_results = cv_results[columns].sort_values(by=\"rank_test_score\")\n",
    "cv_results[\"mean_test_score\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c89218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error after tuning of the bagging regressor:\n",
      "39.60 k$\n"
     ]
    }
   ],
   "source": [
    "target_predicted = search.predict(data_test)\n",
    "print(f\"Mean absolute error after tuning of the bagging regressor:\\n\"\n",
    "      f\"{mean_absolute_error(target_test, target_predicted):.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5051b1",
   "metadata": {},
   "source": [
    "We see that the predictor provided by the bagging regressor does not need much hyperparameter tuning compared to a single decision tree. We see that the bagging regressor provides a predictor for which tuning the hyperparameters is not as important as in the case of fitting a single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a96f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "nbreset": "https://github.com/INRIA/scikit-learn-mooc/raw/master/notebooks/ensemble_ex_01.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
